# -*- coding: utf-8 -*-
"""
Created on Wed Dec 28 12:08:56 2022

@author: Du Ho
"""
Conversion from matlab code to python, handle with text and verify the structure
idea: develop node, define the function tree
develop catchkey, catch the keywords in the matlab function, check if this is built in function or variable
or custom function
+ built in, request, the equivalence
+ matrix will be use np.ndarray, some built in function for matrix we would use broadcasting, etc

A tokenizer or scanner analyzes a string to categorize groups of characters. 
This is a useful first step in writing a compiler or interpreter.

The text categories are specified with regular expressions. The technique is   
to combine those into a single master regular expression and to loop over successive matches:

Questions: should it be equivalent to a compiler?
https://docs.python.org/3/reference/lexical_analysis.html#keywords

Resources:
https://github.com/dabeaz/ply
https://github.com/florianschanda/miss_hit

https://devguide.python.org/internals/compiler/

Abstract
In CPython, the compilation from source code to bytecode involves several steps:
+ Tokenize the source code (Parser/tokenizer.c)
+ Parse the stream of tokens into an Abstract Syntax Tree (Parser/parser.c)
+ Transform AST into a Control Flow Graph (Python/compile.c)
+ Emit bytecode based on the Control Flow Graph (Python/compile.c)
The purpose of this document is to outline how these steps of the process work.
This document does not touch on how parsing works beyond what is needed to explain what is needed for compilation. It is also not exhaustive in terms of the how the entire system works. You will most likely need to read some source to have an exact understanding of all details.